ret
sum(w.days[5,]*ret[5,])
ret
w.days
w.days[1,]
ret[1,]
ret[4,]
ret[5,]
ret[6,]
ret[7,]
ret
px.clean
dim(px.clean)[1]
ret
px.clean
install.packages("quantmod")
library(quantmod)
ROC(px.clean[1:dim(px.clean)[1],]),type='discrete', na.pad=FALSE)
ROC(px.clean[1:dim(px.clean)[1],],type='discrete', na.pad=FALSE)
ROC(px.clean[1:dim(px.clean)[2],],type='discrete', na.pad=FALSE)
px.clean[1,]
px.clean[3,]
dim(px.clean)[1]
ret=log(px.clean[,2:dim(px.clean)[1]])-log(px.clean[,1:(dim(px.clean)[1]-1)])
ROC(px.clean)
px.clean[,2:dim(px.clean)[1]]
px.clean[2:dim(px.clean)[1],]
px.clean[2:dim(px.clean)[1],][2,]
px.clean[3,]
ret
px.clean[6,]
log(px.clean[6,])-log(px.clean[5,])
px.clean[6,]/px.clean[5,]-1
px.clean[6,]
px.clean[5,]
px.clean[5,]-px.clean[6,]
ret
dim(ret)
ret=rbind(rep(0,ncol(ret)),ret)
dim(ret)
index.ret=vector("numeric")
for(i in 1:nrow(ret)){#
	index.ret[i]=sum(ret[i,]*w.days[i,])#
}
ts.plot(index.ret)
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",xlab="Daily log-returns of index")
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")
index.ret
x <- c(12.45,34,4,0,-234,45.6,4)
N=3
ndx <- order(x, decreasing = T)[1:N]
x[ndx]
ndx
indexN=function(N){#
	m=matrix(nrow=nrow(w.days),ncol=N)#
	for(i in 1:nrow(w.days)){#
		ndx <- order(w.days[i,], decreasing = T)[1:N]#
		rbind(ndx,)#
	}#
}
indexN(5)
indexN=function(N){#
	m=matrix(nrow=nrow(w.days),ncol=N)#
	for(i in 1:nrow(w.days)){#
		ndx <- order(w.days[i,], decreasing = T)[1:N]#
		m[i,]=ndx#
	}#
	return(m)#
}
#find the index locations of N largest weights#
indexN=function(N,mat){#
	m=matrix(nrow=nrow(mat),ncol=N)#
	for(i in 1:nrow(mat)){#
		ndx <- order(mat[i,], decreasing = T)[1:N]#
		m[i,]=ndx#
	}#
	return(m)#
}
a=matrix(1:20,nrow=5,ncol=4,byrow=T)
a
indexN(2,a)
a=matrix(rnorm(20),nrow=5,ncol=4,byrow=T)
a
indexN(2,a)
cumul.index.ret=vector("numeric")#
for(i in 2:nrow(index.ret)){#
	cumul.index.ret[1]=100#
	cumul.index.ret[i]=cumul.index.ret[i-1]*(1+index.ret[i-1])#
}
cumul.index.ret=vector("numeric")#
for(i in 2:length(index.ret)){#
	cumul.index.ret[1]=100#
	cumul.index.ret[i]=cumul.index.ret[i-1]*(1+index.ret[i-1])#
}
ts.plot(cumul.index.ret)
par(mfrow=c(2,1))#
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")
a[indexN(2,a)]
indexN(2,1)
indexN(2,a)
indexN(2,a)[1,]
a[indexN(2,a)[1,]]
a
a[1,]
a[1,][indexN(2,a)]
a[1,][indexN(2,a)[1,]]
index.retN=function(N,weights,returns){#
	index.retN=vector("numeric")#
	index.matrix=indexN(N,weights)#
	for(i in 1:nrow(weights)){#
		index.retN[i]=sum(returns[i,][indexN(N,weights)[i,]]*weights[i,][indexN(N,weights)[i,]])#
	}#
	return(index.retN)#
}
a=index.retN(10,w.days,ret)
)
)#
dfdf
index.retN=function(N,weights,returns){#
	start <- Sys.time ()#
	index.retN=vector("numeric"); cumul.index.retN=vector("numeric")#
	cumul.index.retN[1]=100#
	index.matrix=indexN(N,weights)#
	for(i in 1:nrow(weights)){#
		index.retN[i]=sum(returns[i,][indexN(N,weights)[i,]]*weights[i,][indexN(N,weights)[i,]])#
		cumul.index.ret[i+1]=cumul.index.ret[i]*(1+index.ret[i])#
		if(i%%10==0){#
    		time=Sys.time () - start#
    		cat("i=",i,", time spent=",time,"\n")#
    	}#
	}#
	return(list(index.retN,cumul.index.ret))#
}
a=index.retN(10,w.days,ret)
a
dim(w.days)
dim(ret)
index.ret=vector("numeric"); cumul.index.ret=vector("numeric")#
cumul.index.ret[1]=100#
for(i in 1:nrow(ret)){#
	index.ret[i]=sum(ret[i,]*w.days[i,])#
	cumul.index.ret[i+1]=cumul.index.ret[i]*(1+index.ret[i])#
}
par(mfrow=c(2,1))#
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")
setwd("/Users/tillkischkat/Desktop/MSc Statistics/Trimester 3/Statistical Arbitrage/R:MATLAB Code/Spread")
setwd("/Users/tillkischkat/Desktop/MSc Statistics/Trimester 3/Statistical Arbitrage/R:MATLAB Code/Cointegration")#
source("Cointegration_functions.R")#
#
setwd("/Users/tillkischkat/Desktop/MSc Statistics/Trimester 3/Statistical Arbitrage/R:MATLAB Code/Spread")#
source("Spread_functions.R")
source("Spread_functions.R")
index15=index.retN(15,w.days,ret)#
ret15=index15[[1]]#
cumul15=index15[[2]]#
#
par(mfrow=c(2,1))#
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
lines(ret15,col="red")#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")#
lines(cumul15,col="red")
index15=index.retN(1000,w.days,ret)
ret15=index15[[1]]#
cumul15=index15[[2]]#
#
par(mfrow=c(2,1))#
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
lines(ret15,col="red")#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")#
lines(cumul15,col="red")
source("Spread_functions.R")
index15=index.retN(100,w.days,ret)#
ret15=index15[[1]]#
cumul15=index15[[2]]#
#
par(mfrow=c(2,1))#
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
lines(ret15,col="red")#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")#
lines(cumul15,col="red")
index100=index.retN(100,w.days,ret)#
ret100=index100[[1]]#
cumul100=index100[[2]]#
#
par(mfrow=c(2,1))#
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
lines(ret100,col="red")#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")#
lines(cumul100,col="red")
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
lines(ret100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(3,3),col=c("black","red"),cex=0.7)#
#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")#
lines(cumul100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(3,3),col=c("black","red"),cex=0.7)
par(mfrow=c(2,1))#
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
lines(ret100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(3,3),col=c("black","red"),cex=0.7)#
#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")#
lines(cumul100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(3,3),col=c("black","red"),cex=0.7)
par(mfrow=c(2,1))#
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
lines(ret100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.7)#
#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")#
lines(cumul100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.7)
create.spread.opt(cumul.index.ret,cumul.index.ret100,0.1,0.05)
create.spread.opt(cumul.index.ret,cumul100,0.1,0.05)
install.packages("quantmod")#
install.packages("tseries")#
install.packages("fUnitRoots")#
install.packages("Quandl")#
install.packages("urca") #ca.jo#
install.packages("vars")#
install.packages("tsDyn")#
install.packages("HAC")#
library(quantmod)#
library(tseries) #adf.test; kpss.test#
library(fUnitRoots) #adfTest#
library(Quandl)#
library(urca)#
library(vars)#
library(tsDyn) #better Johansen cointegration test#
library(HAC) #H
create.spread.opt(cumul.index.ret,cumul100,0.1,0.05)
par(mfrow=c(2,1))#
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
lines(ret100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.7)#
#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")#
lines(cumul100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.7)
index100=index.retN(200,w.days,ret)#
ret100=index100[[1]]#
cumul100=index100[[2]]#
#
par(mfrow=c(2,1))#
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
lines(ret100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.7)#
#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")#
lines(cumul100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.7)
create.spread.opt(cumul.index.ret,cumul100,0.1,0.05)
setwd("/Users/tillkischkat/Desktop/MSc Statistics/Trimester 3/Statistical Arbitrage/R:MATLAB Code/Cointegration")#
source("Cointegration_functions.R")
setwd("/Users/tillkischkat/Desktop/MSc Statistics/Trimester 3/Statistical Arbitrage/R:MATLAB Code/Spread")#
source("Spread_functions.R")
create.spread.opt(cumul.index.ret,cumul100,0.1,0.05)
par(mfrow=c(2,1))#
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
lines(ret100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.7)#
#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")#
lines(cumul100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.7)
8844/170
for(i in 1:floor(length(cumul.index.ret)/170)){#
	spread=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],cumul100[(170*(i-1)):(170*i)],0.2,0.01)[[1]]#
	print(c(spread,i))#
}
index100=index.retN(100,w.days,ret)#
ret100=index100[[1]]#
cumul100=index100[[2]]
for(i in 1:floor(length(cumul.index.ret)/170)){#
	spread=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],cumul100[(170*(i-1)):(170*i)],0.2,0.01)[[1]]#
	print(c(spread,i))#
}
create.spread.opt(cumul.index.ret,cumul100,0.5,0.05)
create.spread.opt(cumul.index.ret,cumul100,0.4,0.05)
create.spread.opt<-function(s1,s2,cor_thresh,p_thresh){#
	if(length(s1)>length(s2)) s1=s1[1:length(s2)]#
	else s2=s2[1:length(s1)]#
	s1=log(s1); s2=log(s2)#
#
	if(adf.test(s1,k=0)$p.value<p_thresh || adf.test(s2,k=0)$p.value<p_thresh){#
		return("S1 or S2 not I(1)")}#
	if(abs(cor(diff(s1),diff(s2)))<cor_thresh) return("Corr of log-returns below threshold")#
	lm1=lm(s1~s2); lm2=lm(s2~s1)#
	#lm1=rlm(s1~s2,psi=psi.hampel); lm2=rlm(s2~s1,psi=psi.hampel)#
	u1=lm1$coefficients[1]; u2=lm2$coefficients[1]#
	g1=lm1$coefficients[2]; g2=lm2$coefficients[2]#
	z1=lm1$residuals; z2=lm2$residuals#
	lag1=floor(12*(length(z1)/100)^0.25)#
	lag2=floor(12*(length(z2)/100)^0.25)#
#
	while(abs(adfTest(z1,lags=lag1,type="nc")@test$statistic)<1.6 && lag1>0) lag1=lag1-1#
	while(abs(adfTest(z2,lags=lag2,type="nc")@test$statistic)<1.6 && lag2>0) lag2=lag2-1#
	list1=adfTest(z1,lags=lag1,type="nc")#
	list2=adfTest(z2,lags=lag2,type="nc")#
#
	statistic1=list1@test$statistic; statistic2=list2@test$statistic#
	p.val1=list1@test$p.val; p.val2=list2@test$p.val#
	if(statistic1<statistic2 && p.val1<=0.05 && kpss.test(z1)$p.value>=0.05){#
		#cat("s1=g*s2+u\n")#
		return(list(c(u1,g1,statistic1),"z1"=z1))#
	}else if(statistic2<statistic1 && p.val2<=0.05 && kpss.test(z2)$p.value>=0.05){#
		#cat("s2=g*s1+u\n")#
		return(list(c(u2,g2,statistic2),"z2"=z2))#
	}else{#
		return("No Cointegration between S1 and S2")#
	}#
}
for(i in 1:floor(length(cumul.index.ret)/170)){#
	spread=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],cumul100[(170*(i-1)):(170*i)],0.2,0.01)[[1]]#
	print(c(spread,i))#
}
for(i in 1:floor(length(cumul.index.ret)/170)){#
	spread=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],cumul100[(170*(i-1)):(170*i)],0.5,0.01)[[1]]#
	print(c(spread,i))#
}
for(i in 1:floor(length(cumul.index.ret)/170)){#
	spread=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],cumul100[(170*(i-1)):(170*i)],0.8,0.01)[[1]]#
	print(c(spread,i))#
}
for(i in 1:floor(length(cumul.index.ret)/170)){#
	spread=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],cumul100[(170*(i-1)):(170*i)],0.9,0.01)[[1]]#
	print(c(spread,i))#
}
spread
for(i in 1:floor(length(cumul.index.ret)/170)){#
	spread=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],cumul100[(170*(i-1)):(170*i)],0.9,0.01)[[1]]#
	print(c(spread,i))#
	rm(spread)#
}
i=12
c=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],cumul100[(170*(i-1)):(170*i)],0.9,0.01)[[2]]
ts.plot(c)
index100=index.retN(30,w.days,ret)#
ret100=index100[[1]]#
cumul100=index100[[2]]#
#
par(mfrow=c(2,1))#
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
lines(ret100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.7)#
#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")#
lines(cumul100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.7)#
#
#check for cointegration#
create.spread.opt(cumul.index.ret,cumul100,0.4,0.05)#
#
for(i in 1:floor(length(cumul.index.ret)/170)){#
	spread=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],cumul100[(170*(i-1)):(170*i)],0.9,0.01)[[1]]#
	print(c(spread,i))#
	rm(spread)#
}
#100 stock in chosen index#
index100=index.retN(100,w.days,ret)#
ret100=index100[[1]]#
cumul100=index100[[2]]#
#
par(mfrow=c(2,1))#
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
lines(ret100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.7)#
#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")#
lines(cumul100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.7)#
#
#check for cointegration#
create.spread.opt(cumul.index.ret,cumul100,0.4,0.05)#
#
for(i in 1:floor(length(cumul.index.ret)/170)){#
	spread=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],cumul100[(170*(i-1)):(170*i)],0.9,0.01)[[1]]#
	print(c(spread,i))#
	rm(spread)#
}
create.spread.opt<-function(s1,s2,cor_thresh,p_thresh){#
	if(length(s1)>length(s2)) s1=s1[1:length(s2)]#
	else s2=s2[1:length(s1)]#
	s1=log(s1); s2=log(s2)#
#
	if(adf.test(s1,k=0)$p.value<p_thresh || adf.test(s2,k=0)$p.value<p_thresh){#
		return("S1 or S2 not I(1)")}#
	if(abs(cor(diff(s1),diff(s2)))<cor_thresh) return("Corr of log-returns below threshold")#
	lm1=lm(s1~s2); lm2=lm(s2~s1)#
	#lm1=rlm(s1~s2,psi=psi.hampel); lm2=rlm(s2~s1,psi=psi.hampel)#
	u1=lm1$coefficients[1]; u2=lm2$coefficients[1]#
	g1=lm1$coefficients[2]; g2=lm2$coefficients[2]#
	z1=lm1$residuals; z2=lm2$residuals#
	lag1=floor(12*(length(z1)/100)^0.25)#
	lag2=floor(12*(length(z2)/100)^0.25)#
#
	while(abs(adfTest(z1,lags=lag1,type="nc")@test$statistic)<1.6 && lag1>0) lag1=lag1-1#
	while(abs(adfTest(z2,lags=lag2,type="nc")@test$statistic)<1.6 && lag2>0) lag2=lag2-1#
	list1=adfTest(z1,lags=lag1,type="nc")#
	list2=adfTest(z2,lags=lag2,type="nc")#
#
	statistic1=list1@test$statistic; statistic2=list2@test$statistic#
	p.val1=list1@test$p.val; p.val2=list2@test$p.val#
	if(statistic1<statistic2 && p.val1<=0.01 && kpss.test(z1)$p.value>=0.1){#
		#cat("s1=g*s2+u\n")#
		return(list(c(u1,g1,statistic1),"z1"=z1))#
	}else if(statistic2<statistic1 && p.val2<=0.01 && kpss.test(z2)$p.value>=0.1){#
		#cat("s2=g*s1+u\n")#
		return(list(c(u2,g2,statistic2),"z2"=z2))#
	}else{#
		return("No Cointegration between S1 and S2")#
	}#
}
index100=index.retN(20,w.days,ret)#
ret100=index100[[1]]#
cumul100=index100[[2]]#
#
par(mfrow=c(2,1))#
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
lines(ret100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.7)#
#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")#
lines(cumul100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.7)#
#
#check for cointegration#
create.spread.opt(cumul.index.ret,cumul100,0.4,0.05)#
#
for(i in 1:floor(length(cumul.index.ret)/170)){#
	spread=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],cumul100[(170*(i-1)):(170*i)],0.9,0.01)[[1]]#
	print(c(spread,i))#
	rm(spread)#
}
index100=index.retN(100,w.days,ret)#
ret100=index100[[1]]#
cumul100=index100[[2]]#
#
par(mfrow=c(2,1))#
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
lines(ret100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.5)#
#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")#
lines(cumul100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.5)#
#
#check for cointegration#
create.spread.opt(cumul.index.ret,cumul100,0.4,0.05)#
#
for(i in 1:floor(length(cumul.index.ret)/170)){#
	spread=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],cumul100[(170*(i-1)):(170*i)],0.9,0.01)[[1]]#
	print(c(spread,i))#
	rm(spread)#
}
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")#
lines(cumul100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.5)
#### check for all combinations#
for(j in 15:50,by=5){#
	index.j=index.retN(j,w.days,ret)[[2]]#
	for(i in 1:floor(length(cumul.index.ret)/170)){#
		spread=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],index.j[(170*(i-1)):(170*i)],0.9,0.01)[[1]]#
		print(c(spread,i))#
		rm(spread)#
	}#
}
for(j in seq(15,50,5)){#
	index.j=index.retN(j,w.days,ret)[[2]]#
	for(i in 1:floor(length(cumul.index.ret)/170)){#
		spread=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],index.j[(170*(i-1)):(170*i)],0.9,0.01)[[1]]#
		print(c(spread,i))#
		rm(spread)#
	}#
}
#### check for all combinations#
for(j in seq(15,50,5)){#
	cat("Number of stocks=",j,"\n")#
	index.j=index.retN(j,w.days,ret)[[2]]#
	for(i in 1:floor(length(cumul.index.ret)/170)){#
		spread=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],index.j[(170*(i-1)):(170*i)],0.9,0.01)[[1]]#
		print(c(spread,i))#
		rm(spread)#
	}#
}
for(j in seq(15,50,5)){#
	cat("Number of stocks=",j,"\n\n")#
	index.j=index.retN(j,w.days,ret)[[2]]#
	for(i in 1:floor(length(cumul.index.ret)/170)){#
		spread=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],index.j[(170*(i-1)):(170*i)],0.9,0.01)[[1]]#
		print(c(spread,i))#
		rm(spread)#
	}#
}
for(j in seq(15,50,5)){#
	cat("\nNumber of stocks=",j,"\n\n")#
	index.j=index.retN(j,w.days,ret)[[2]]#
	for(i in 1:floor(length(cumul.index.ret)/170)){#
		spread=create.spread.opt(cumul.index.ret[(170*(i-1)):(170*i)],index.j[(170*(i-1)):(170*i)],0.9,0.01)[[1]]#
		print(c(spread,i))#
		rm(spread)#
	}#
}
#### check for all combinations#
from=15; to=50; by=5; days=250; cor_thresh=0.9; pval_thresh=0.01#
for(j in seq(from,to,by)){#
	cat("\nNumber of stocks=",j,"\n\n")#
	index.j=index.retN(j,w.days,ret)[[2]]#
	for(i in 1:floor(length(cumul.index.ret)/days)){#
		spread=create.spread.opt(cumul.index.ret[(days*(i-1)):(days*i)],index.j[(days*(i-1)):(days*i)],cor_thrsh,pval_thresh)[[1]]#
		print(c(spread,i))#
		rm(spread)#
	}#
}
from=15; to=50; by=5; days=250; cor_thresh=0.9; pval_thresh=0.01#
for(j in seq(from,to,by)){#
	cat("\nNumber of stocks=",j,"\n\n")#
	index.j=index.retN(j,w.days,ret)[[2]]#
	for(i in 1:floor(length(cumul.index.ret)/days)){#
		spread=create.spread.opt(cumul.index.ret[(days*(i-1)):(days*i)],index.j[(days*(i-1)):(days*i)],cor_thresh,pval_thresh)[[1]]#
		print(c(spread,i))#
		rm(spread)#
	}#
}
from=15; to=50; by=5; days=170; cor_thresh=0.9; pval_thresh=0.01
for(j in seq(from,to,by)){#
	cat("\nNumber of stocks=",j,"\n\n")#
	index.j=index.retN(j,w.days,ret)[[2]]#
	for(i in 1:floor(length(cumul.index.ret)/days)){#
		spread=create.spread.opt(cumul.index.ret[(days*(i-1)):(days*i)],index.j[(days*(i-1)):(days*i)],cor_thresh,pval_thresh)[[1]]#
		print(c(spread,i))#
		rm(spread)#
	}#
}
par(mfrow=c(2,1))#
ts.plot(index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily log-returns of index")#
lines(ret100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.5)#
#
ts.plot(cumul.index.ret,main="S&P 500 1.1.1990-19.3.2014",ylab="Daily cumulative log-returns of index")#
lines(cumul100,col="red",lty=3)#
legend("bottomright",c("All stocks","Largest 100 stocks"),lty=c(1,3),col=c("black","red"),cex=0.5)
from=15; to=50; by=5; days=170; cor_thresh=0.9; pval_thresh=0.01#
for(j in seq(from,to,by)){#
	cat("\nNumber of stocks=",j,"\n\n")#
	index.j=index.retN(j,w.days,ret)[[2]]#
	for(i in 1:floor(length(cumul.index.ret)/days)){#
		spread=create.spread.opt(cumul.index.ret[(days*(i-1)):(days*i)],index.j[(days*(i-1)):(days*i)],cor_thresh,pval_thresh)[[1]]#
		print(c(spread,i))#
		rm(spread)#
	}#
}
j=20;i=12
spread=create.spread.opt(cumul.index.ret[(days*(i-1)):(days*i)],index.j[(days*(i-1)):(days*i)],cor_thresh,pval_thresh)[[2]]
ts.plot(spread)
i
j
index.j=index.retN(j,w.days,ret)[[2]]
spread=create.spread.opt(cumul.index.ret[(days*(i-1)):(days*i)],index.j[(days*(i-1)):(days*i)],cor_thresh,pval_thresh)[[1]]
ts.plot(spread)
j
index.ja
index.j
spread=create.spread.opt(cumul.index.ret[(days*(i-1)):(days*i)],index.j[(days*(i-1)):(days*i)],cor_thresh,pval_thresh)[[1]]
spread
spread=create.spread.opt(cumul.index.ret[(days*(i-1)):(days*i)],index.j[(days*(i-1)):(days*i)],cor_thresh,pval_thresh)[[2]]
ts.plot(spread)
acf(spread)
nsteps=2500; N=1000
y=spread
test=gmhp.full(rho_0=0.5,tau_0=0.7,sigma_0=0.8,sigma_rho=0.5,sigma_tau=0.7,sigma_sigma=0.9,nsteps=nsteps,y=y) # sigmas tuning 0.5, 0.7, 0.9
setwd("/Users/tillkischkat/Desktop/MSc Statistics/Trimester 3/Statistical Arbitrage/R:MATLAB Code/PMCMC R")#
install.packages("truncnorm")#
install.packages("pscl")#
install.packages("coda")#
library(truncnorm)#
library(pscl)#
library(coda)#
source("PMCMC_functions.R")
test=gmhp.full(rho_0=0.5,tau_0=0.7,sigma_0=0.8,sigma_rho=0.5,sigma_tau=0.7,sigma_sigma=0.9,nsteps=nsteps,y=y) # sigmas tuning 0.5, 0.7, 0.9
df=2
test=gmhp.full(rho_0=0.5,tau_0=0.7,sigma_0=0.8,sigma_rho=0.5,sigma_tau=0.7,sigma_sigma=0.9,nsteps=nsteps,y=y) # sigmas tuning 0.5, 0.7, 0.9
test.rho=test[[1]][-(1:(floor(nsteps/10)))]#
test.tau=test[[2]][-(1:(floor(nsteps/10)))]#
test.sigma=test[[3]][-(1:(floor(nsteps/10)))]#
loglik=log(test[[4]][1:(floor(nsteps/10))])#
#
# acceptance probability#
1-rejectionRate(mcmc(test.rho)) #0.17#
1-rejectionRate(mcmc(test.tau)) #0.27#
1-rejectionRate(mcmc(test.sigma)) #0.26#
#
par(mfrow=c(2,2))#
hist(test.rho,breaks=50,main="Histogram of rho with N=1000",xlab="Rho")#
hist(test.tau,breaks=50,main="Histogram of tau with N=1000",xlab="Tau")#
hist(test.sigma,breaks=50,main="Histogram of sigma with N=1000",xlab="Sigma")#
plot(loglik,main="Burn-in phase",xlab="Iterations",ylab="log-likelihood",type="l")
var(ret100-index.ret)
index100=index.retN(20,w.days,ret)
ret100=index100[[1]]#
cumul100=index100[[2]]
var(ret100-index.ret)
index100=index.retN(30,w.days,ret)#
ret100=index100[[1]]#
cumul100=index100[[2]]#
#
#diagnostic check#
var(ret100-index.ret)
sqrt(3.338979e-05)
sd(ret100-index.ret)
library(doParallel)
install.packages("doParallel")
library(doParallel)
detectCores()
getDoParWorkers()
cl=makeCluster(4)
registerDoParallel(cl)
getDoParWorkers()
test=gmhp.full(rho_0=0.5,tau_0=0.7,sigma_0=0.8,sigma_rho=0.5,sigma_tau=0.7,sigma_sigma=0.9,nsteps=nsteps,y=y) # sigmas tuning 0.5, 0.7, 0.9
test.rho=test[[1]][-(1:(floor(nsteps/10)))]#
test.tau=test[[2]][-(1:(floor(nsteps/10)))]#
test.sigma=test[[3]][-(1:(floor(nsteps/10)))]#
loglik=log(test[[4]][1:(floor(nsteps/10))])#
#
# acceptance probability#
1-rejectionRate(mcmc(test.rho)) #0.17#
1-rejectionRate(mcmc(test.tau)) #0.27#
1-rejectionRate(mcmc(test.sigma)) #0.2
par(mfrow=c(2,2))#
hist(test.rho,breaks=50,main="Histogram of rho with N=1000",xlab="Rho")#
hist(test.tau,breaks=50,main="Histogram of tau with N=1000",xlab="Tau")#
hist(test.sigma,breaks=50,main="Histogram of sigma with N=1000",xlab="Sigma")#
plot(loglik,main="Burn-in phase",xlab="Iterations",ylab="log-likelihood",type="l")
### Diagnostics#
summary(as.mcmc(test.rho)) #mean 0.80#
summary(as.mcmc(test.tau)) #mean 0.92#
summary(as.mcmc(test.sigma)) #mean 0.45
par(mfrow=c(3,2))#
ts.plot(test.rho,main="Trace Plot",ylab=expression(rho))#
acf(test.rho,main=expression(rho))#
ts.plot(test.tau,main="Trace Plot",ylab=expression(tau))#
acf(test.tau,main=expression(tau))#
ts.plot(test.sigma,main="Trace Plot",ylab=expression(sigma))#
acf(test.sigma,main=expression(sigma))
ts.plot(test.rho)
ts.plot(test.sigma)
a=rnorm(1e8)
?sample
sample
rnorm
install.packages("urca") #ca.jo
library(urca)
?ca.jo
?sample
densigamma(0.5,0.5,0.5)
library(pscl)
densigamma(0.5,0.5,0.5)
densigamma(0.5,0.3,0.9)
?densigamma
densigamma(0.5,0.9,0.3)
dinvgamma(0.5,0.9,0.3)
densigamma(10,0.9,0.3)
densigamma(1,0.9,0.3)
densigamma(1,0.4,0.5)
?dlnorm
20*0.2+30*0.4
10+0.8+20+0.6*30
p<-function(N,T,y,rho,tau,sigma,df){#
	yy=matrix(y[1:(T+1)],byrow=TRUE,nrow=N,ncol=T+1)#
	xx=matrix(nrow=N,ncol=T+1)#
	w=matrix(nrow=N,ncol=T+1)#
	ww=matrix(nrow=N,ncol=T+1)#
	xx_res=matrix(nrow=N,ncol=T+1)#
	xx[,1]=rt(N,df=df)#
	w[,1]=1/N#
	ww[,1]=w[,1]/sum(w[,1])#
	xx_res[,1]=xx[,1]#
	for(i in 1:T){#
		xx[,i+1]=rho*xx_res[,i]+tau*rt(N,df=df)#
		w[,i+1]=1/sigma*dt((yy[,i+1]-xx[,i+1])/sigma,df=df)		#
		ww[,i+1]=w[,i+1]/sum(w[,i+1])#
		#adaptive resampling#
		if(1/sum(ww[,i+1]^2)>N/3) xx_res[,i+1]=xx[,i+1]#
		else xx_res[,i+1]=sample(xx[,i+1],size=N,prob=ww[,i+1],replace=TRUE)#
	}#
	#p=prod(colMeans(w))#
	p=log(colMeans(w))#
	return(p)#
}
rho=0.8; tau=1; sigma=0.5; T=250; df=2#
#
### Calculate y_[0:T] and trajectory x*_[0:T]#
x=vector("numeric")#
y=vector("numeric")#
x[1]=rt(1,df=df)#
for(n in 1:(T+1)){#
	x[n+1]=rho*x[n]+tau*rt(1,df=df)#
	y[n]=x[n]+sigma*rt(1,df=df)#
}
df
p<-(N=N,T=T,y=y,rho=rho,tau=tau,sigma=sigma,df=df)
p<-p(N=N,T=T,y=y,rho=rho,tau=tau,sigma=sigma,df=df)
N=1000
p<-p(N=N,T=T,y=y,rho=rho,tau=tau,sigma=sigma,df=df)
plot(p,type="l")
p<-function(N,T,y,rho,tau,sigma,df){#
	yy=matrix(y[1:(T+1)],byrow=TRUE,nrow=N,ncol=T+1)#
	xx=matrix(nrow=N,ncol=T+1)#
	w=matrix(nrow=N,ncol=T+1)#
	ww=matrix(nrow=N,ncol=T+1)#
	xx_res=matrix(nrow=N,ncol=T+1)#
	xx[,1]=rt(N,df=df)#
	w[,1]=1/N#
	ww[,1]=w[,1]/sum(w[,1])#
	xx_res[,1]=xx[,1]#
	for(i in 1:T){#
		xx[,i+1]=rho*xx_res[,i]+tau*rt(N,df=df)#
		w[,i+1]=1/sigma*dt((yy[,i+1]-xx[,i+1])/sigma,df=df)		#
		ww[,i+1]=w[,i+1]/sum(w[,i+1])#
		#adaptive resampling#
		if(1/sum(ww[,i+1]^2)>N/3) xx_res[,i+1]=xx[,i+1]#
		else xx_res[,i+1]=sample(xx[,i+1],size=N,prob=ww[,i+1],replace=TRUE)#
	}#
	p=prod(colMeans(w))#
	#p=log(colMeans(w))#
	return(p)#
}
p<-p(N=N,T=T,y=y,rho=rho,tau=tau,sigma=sigma,df=df)
p
T
p<-function(N,T,y,rho,tau,sigma,df){#
	yy=matrix(y[1:(T+1)],byrow=TRUE,nrow=N,ncol=T+1)#
	xx=matrix(nrow=N,ncol=T+1)#
	w=matrix(nrow=N,ncol=T+1)#
	ww=matrix(nrow=N,ncol=T+1)#
	xx_res=matrix(nrow=N,ncol=T+1)#
	xx[,1]=rt(N,df=df)#
	w[,1]=1/N#
	ww[,1]=w[,1]/sum(w[,1])#
	xx_res[,1]=xx[,1]#
	for(i in 1:T){#
		xx[,i+1]=rho*xx_res[,i]+tau*rt(N,df=df)#
		w[,i+1]=1/sigma*dt((yy[,i+1]-xx[,i+1])/sigma,df=df)		#
		ww[,i+1]=w[,i+1]/sum(w[,i+1])#
		#adaptive resampling#
		if(1/sum(ww[,i+1]^2)>N/3) xx_res[,i+1]=xx[,i+1]#
		else xx_res[,i+1]=sample(xx[,i+1],size=N,prob=ww[,i+1],replace=TRUE)#
	}#
	p=prod(colMeans(w))#
	#p=log(colMeans(w))#
	return(p)#
}
p<-p(N=N,T=T,y=y,rho=rho,tau=tau,sigma=sigma,df=df)
sum(p)
p<-function(N,T,y,rho,tau,sigma,df){#
	yy=matrix(y[1:(T+1)],byrow=TRUE,nrow=N,ncol=T+1)#
	xx=matrix(nrow=N,ncol=T+1)#
	w=matrix(nrow=N,ncol=T+1)#
	ww=matrix(nrow=N,ncol=T+1)#
	xx_res=matrix(nrow=N,ncol=T+1)#
	xx[,1]=rt(N,df=df)#
	w[,1]=1/N#
	ww[,1]=w[,1]/sum(w[,1])#
	xx_res[,1]=xx[,1]#
	for(i in 1:T){#
		xx[,i+1]=rho*xx_res[,i]+tau*rt(N,df=df)#
		w[,i+1]=1/sigma*dt((yy[,i+1]-xx[,i+1])/sigma,df=df)		#
		ww[,i+1]=w[,i+1]/sum(w[,i+1])#
		#adaptive resampling#
		if(1/sum(ww[,i+1]^2)>N/3) xx_res[,i+1]=xx[,i+1]#
		else xx_res[,i+1]=sample(xx[,i+1],size=N,prob=ww[,i+1],replace=TRUE)#
	}#
	#p=prod(colMeans(w))#
	p=log(colMeans(w))#
	return(p)#
}
p<-p(N=N,T=T,y=y,rho=rho,tau=tau,sigma=sigma,df=df)
sum(p)
p<-function(N,T,y,rho,tau,sigma,df){#
	yy=matrix(y[1:(T+1)],byrow=TRUE,nrow=N,ncol=T+1)#
	xx=matrix(nrow=N,ncol=T+1)#
	w=matrix(nrow=N,ncol=T+1)#
	ww=matrix(nrow=N,ncol=T+1)#
	xx_res=matrix(nrow=N,ncol=T+1)#
	xx[,1]=rt(N,df=df)#
	w[,1]=1/N#
	ww[,1]=w[,1]/sum(w[,1])#
	xx_res[,1]=xx[,1]#
	for(i in 1:T){#
		xx[,i+1]=rho*xx_res[,i]+tau*rt(N,df=df)#
		w[,i+1]=1/sigma*dt((yy[,i+1]-xx[,i+1])/sigma,df=df)		#
		ww[,i+1]=w[,i+1]/sum(w[,i+1])#
		#adaptive resampling#
		if(1/sum(ww[,i+1]^2)>N/3) xx_res[,i+1]=xx[,i+1]#
		else xx_res[,i+1]=sample(xx[,i+1],size=N,prob=ww[,i+1],replace=TRUE)#
	}#
	#p=prod(colMeans(w))#
	#p=log(colMeans(w))#
	return(colMeans(xx))#
}
p<-p(N=N,T=T,y=y,rho=rho,tau=tau,sigma=sigma,df=df)
plot(p,type="l")
p<-function(N,T,y,rho,tau,sigma,df){#
	yy=matrix(y[1:(T+1)],byrow=TRUE,nrow=N,ncol=T+1)#
	xx=matrix(nrow=N,ncol=T+1)#
	w=matrix(nrow=N,ncol=T+1)#
	ww=matrix(nrow=N,ncol=T+1)#
	xx_res=matrix(nrow=N,ncol=T+1)#
	xx[,1]=rt(N,df=df)#
	w[,1]=1/N#
	ww[,1]=w[,1]/sum(w[,1])#
	xx_res[,1]=xx[,1]#
	for(i in 1:T){#
		xx[,i+1]=rho*xx_res[,i]+tau*rt(N,df=df)#
		w[,i+1]=1/sigma*dt((yy[,i+1]-xx[,i+1])/sigma,df=df)		#
		ww[,i+1]=w[,i+1]/sum(w[,i+1])#
		#adaptive resampling#
		if(1/sum(ww[,i+1]^2)>N/3) xx_res[,i+1]=xx[,i+1]#
		else xx_res[,i+1]=sample(xx[,i+1],size=N,prob=ww[,i+1],replace=TRUE)#
	}#
	#p=prod(colMeans(w))#
	#p=log(colMeans(w))#
	return(colMeans(xx_res))#
}
p<-p(N=N,T=T,y=y,rho=rho,tau=tau,sigma=sigma,df=df)
plot(p,type="l")
rm(list=ls())#
setwd("/Users/tillkischkat/Desktop/MSc Statistics/Trimester 3/Statistical Arbitrage/R:MATLAB Code/PMCMC R")#
#install.packages("truncnorm")#
#install.packages("pscl")#
#install.packages("coda")#
#install.packages("doParallel")#
library(truncnorm)#
library(pscl)#
library(coda)#
library(doParallel)#
source("PMCMC_functions.R")#
#
detectCores()#
getDoParWorkers()#
cl=makeCluster(4)#
registerDoParallel(cl)#
#
set.seed(128)#
rho=0.8; tau=1; sigma=0.5; T=100; df=2#
#
### Calculate y_[0:T] and trajectory x*_[0:T]#
x=vector("numeric")#
y=vector("numeric")#
x[1]=rt(1,df=df)#
for(n in 1:(T+1)){#
	x[n+1]=rho*x[n]+tau*rt(1,df=df)#
	y[n]=x[n]+sigma*rt(1,df=df)#
}
setwd("/Users/tillkischkat/Desktop/MSc Statistics/Trimester 3/Statistical Arbitrage/R:MATLAB Code/PMCMC R")#
#install.packages("truncnorm")#
#install.packages("pscl")#
#install.packages("coda")#
#install.packages("doParallel")#
library(truncnorm)#
library(pscl)#
library(coda)#
library(doParallel)#
source("PMCMC_functions.R")#
#
detectCores()#
getDoParWorkers()#
cl=makeCluster(4)#
registerDoParallel(cl)#
#
set.seed(128)#
rho=0.8; tau=1; sigma=0.5; T=500; df=2#
#
### Calculate y_[0:T] and trajectory x*_[0:T]#
x=vector("numeric")#
y=vector("numeric")#
x[1]=rt(1,df=df)#
for(n in 1:(T+1)){#
	x[n+1]=rho*x[n]+tau*rt(1,df=df)#
	y[n]=x[n]+sigma*rt(1,df=df)#
}
nsteps=2500; N=1000
test=gmhp.full(rho_0=0.5,tau_0=0.7,sigma_0=0.8,sigma_rho=0.1,sigma_tau=0.3,sigma_sigma=0.4,nsteps=nsteps,y=y) # sigmas tuning 0.5, 0.7, 0.9
test=gmhp.full(rho_0=0.5,tau_0=0.7,sigma_0=0.8,sigma_rho=0.1,sigma_tau=0.3,sigma_sigma=0.4,nsteps=nsteps,y=y) # sigmas tuning 0.5, 0.7, 0.9
test=gmhp.full(rho_0=0.5,tau_0=0.7,sigma_0=0.8,sigma_rho=0.5,sigma_tau=0.7,sigma_sigma=0.9,nsteps=nsteps,y=y) # sigmas tuning 0.5, 0.7, 0.9
test=gmhp.full(rho_0=0.8,tau_0=1,sigma_0=0.5,sigma_rho=0.5,sigma_tau=0.7,sigma_sigma=0.9,nsteps=nsteps,y=y) # sigmas tuning 0.5, 0.7, 0.9
rho=0.8; tau=1; sigma=0.5; T=500; df=2#
#
### Calculate y_[0:T] and trajectory x*_[0:T]#
x=vector("numeric")#
y=vector("numeric")#
x[1]=rt(1,df=df)#
for(n in 1:(T+1)){#
	x[n+1]=rho*x[n]+tau*rt(1,df=df)#
	y[n]=x[n]+sigma*rt(1,df=df)#
}
test=gmhp.full(rho_0=0.8,tau_0=1,sigma_0=0.5,sigma_rho=0.5,sigma_tau=0.7,sigma_sigma=0.9,nsteps=nsteps,y=y) # sigmas tuning 0.5, 0.7, 0.9
source("PMCMC_functions.R")
test=gmhp.full(rho_0=0.8,tau_0=1,sigma_0=0.5,sigma_rho=0.5,sigma_tau=0.7,sigma_sigma=0.9,nsteps=nsteps,y=y) # sigmas tuning 0.5, 0.7, 0.9
test=gmhp.full(rho_0=0.8,tau_0=1,sigma_0=0.5,sigma_rho=0.5,sigma_tau=0.7,sigma_sigma=0.9,nsteps=nsteps,y=y) # sigmas tuning 0.5, 0.7, 0.9
test=gmhp.full(rho_0=0.8,tau_0=1,sigma_0=0.5,sigma_rho=0.5,sigma_tau=0.7,sigma_sigma=0.9,nsteps=nsteps,y=y) # sigmas tuning 0.5, 0.7, 0.9
test=gmhp.full(rho_0=0.8,tau_0=1,sigma_0=0.5,sigma_rho=0.5,sigma_tau=0.7,sigma_sigma=0.9,nsteps=nsteps,y=y) # sigmas tuning 0.5, 0.7, 0.9
test=gmhp.full(rho_0=0.8,tau_0=1,sigma_0=0.5,sigma_rho=0.5,sigma_tau=0.7,sigma_sigma=0.9,nsteps=nsteps,y=y) # sigmas tuning 0.5, 0.7, 0.9
test=gmhp.full(rho_0=0.8,tau_0=1,sigma_0=0.5,sigma_rho=0.5,sigma_tau=0.7,sigma_sigma=0.9,nsteps=nsteps,y=y) # sigmas tuning 0.5, 0.7, 0.9
rho=0.8; tau=1; sigma=0.5; T=100; df=2#
#
### Calculate y_[0:T] and trajectory x*_[0:T]#
x=vector("numeric")#
y=vector("numeric")#
x[1]=rt(1,df=df)#
for(n in 1:(T+1)){#
	x[n+1]=rho*x[n]+tau*rt(1,df=df)#
	y[n]=x[n]+sigma*rt(1,df=df)#
}
test=gmhp.full(rho_0=0.8,tau_0=1,sigma_0=0.5,sigma_rho=0.5,sigma_tau=0.7,sigma_sigma=0.9,nsteps=nsteps,y=y) # sigmas tuning 0.5, 0.7, 0.9
